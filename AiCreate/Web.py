import streamlit as st
import cv2
import numpy as np
import os
import gdown
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import time

def show():
    # üîπ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google Drive File ID ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    GDRIVE_FILE_ID = "1d2UdtGOP-R0Hdg3vatxTWVH2tNyYtfo9"
    MODEL_PATH = "NNmodel.h5"

    # üîπ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å Google Drive
    if not os.path.exists(MODEL_PATH):
        st.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Google Drive...")
        gdown.download(f"https://drive.google.com/uc?id={GDRIVE_FILE_ID}", MODEL_PATH, quiet=False)

    # üîπ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏≤
    model = load_model(MODEL_PATH)
    st.success("‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

    # üîπ Map label index ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™
    class_labels = {0: "Angry", 1: "Happy", 2: "Normal", 3: "Sleep"}

    # üîπ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û
    def predict_emotion(frame):
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))

        if len(faces) == 0:
            return None, None

        for (x, y, w, h) in faces:
            face = frame[y:y+h, x:x+w]
            face = cv2.resize(face, (200, 200))
            face_array = image.img_to_array(face) / 255.0
            face_array = np.expand_dims(face_array, axis=0)

            prediction = model.predict(face_array)
            predicted_class = np.argmax(prediction)
            predicted_label = class_labels[predicted_class]

            return predicted_label, (x, y, w, h)

    # üîπ ‡∏™‡πà‡∏ß‡∏ô UI ‡∏Ç‡∏≠‡∏á Streamlit
    st.title("‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤")

    # üîπ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
    video_capture = cv2.VideoCapture(0)

    if not video_capture.isOpened():
        st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ! ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠")
        st.stop()

    frame_placeholder = st.empty()
    prediction_placeholder = st.empty()

    st.write("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏´‡πâ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏≤‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏π‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢!")

    # üîπ ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á
    while True:
        ret, frame = video_capture.read()
        if not ret:
            st.error("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
            break

        frame = cv2.flip(frame, 1)
        emotion, face_coords = predict_emotion(frame)

        if face_coords:
            x, y, w, h = face_coords
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_placeholder.image(frame_rgb, channels="RGB")

        if emotion:
            prediction_placeholder.write(f"### ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö: *{emotion}*")

        time.sleep(0)  # ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•

    video_capture.release()
    cv2.destroyAllWindows()